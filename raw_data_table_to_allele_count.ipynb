{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e178ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44004353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucleotide_file_to_counts_single_allele(nucleotide_file_name, reference_sequence, site_start, site_end, timepoints, rep, table_col_name, save_path):\n",
    "    codon_length = 3\n",
    "    df_data = pd.read_csv(nucleotide_file_name, low_memory=False)\n",
    "    df_data = df_data.fillna(0)\n",
    "    df_data = df_data.drop([0, 1, 2], axis = 0)\n",
    "    df_data = df_data.drop(df_data.columns[0], axis = 1)\n",
    "    df_data.reset_index(drop=True, inplace=True)\n",
    "    df_data.columns = df_data.iloc[0]\n",
    "    df_data = df_data.drop([0], axis = 0)\n",
    "\n",
    "    CODONS = ['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT',   # Tri-nucleotide units table\n",
    "              'AGA', 'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT',\n",
    "              'CAA', 'CAC', 'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT',\n",
    "              'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC', 'CTG', 'CTT',\n",
    "              'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT',\n",
    "              'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT',\n",
    "              'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT',\n",
    "              'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG', 'TTT']   \n",
    "    \n",
    "    df_data[df_data['hgvs_nt'].str.contains('X', regex=False)]\n",
    "    df_data = df_data[~df_data.hgvs_nt.str.contains('X', regex=False)]\n",
    "    \n",
    "    df_frequency = df_data.loc[:,df_data.columns[2]:].astype('float')\n",
    "    df_frequency.loc[:,df_frequency.columns[2]:] = df_frequency.loc[:,df_frequency.columns[2]:].div(df_frequency.sum(axis=1),axis=0)\n",
    "    site_list = list(range(site_start, site_end+1))\n",
    "    raw_codon = [reference_sequence[i:i+codon_length] for i in range(0, len(reference_sequence), codon_length)]\n",
    "    allele_counts_columns = ['replicate', 'generation', 'site', 'codon', 'counts']\n",
    "    allele_counts_table = df_data[table_col_name]\n",
    "\n",
    "    temp = allele_counts_table.columns.tolist()[0]\n",
    "    allele_counts_table = allele_counts_table.rename(columns={temp: 'variants'})\n",
    "    count_table_columns = allele_counts_table.columns.tolist()\n",
    "    allele_counts_table[allele_counts_table['variants'] == '_wt']\n",
    "\n",
    "    allele_counts_table_no_wt = allele_counts_table.drop(allele_counts_table.index[allele_counts_table['variants'] == '_wt'])\n",
    "\n",
    "    total_count = []\n",
    "    total_mut = []\n",
    "    total_wt  = []\n",
    "    \n",
    "    for i in range(len(timepoints)):\n",
    "        counts_all = allele_counts_table[count_table_columns[i+1]].tolist()\n",
    "        temp = [int(integer) for integer in counts_all]\n",
    "        counts_all = temp\n",
    "        summation_all = sum(counts_all)\n",
    "        total_count.append(summation_all)\n",
    "        counts_mut = allele_counts_table_no_wt[count_table_columns[i+1]].tolist()\n",
    "        temp = [int(integer) for integer in counts_mut]\n",
    "        counts_mut = temp\n",
    "        summation_mut = sum(counts_mut)\n",
    "        total_mut.append(summation_mut)\n",
    "        summation_wt = summation_all - summation_mut\n",
    "        total_wt.append(summation_wt)\n",
    "#     print(total_count, total_mut, total_wt)\n",
    "    \n",
    "    codon_allele_dict = {}\n",
    "    for gen in timepoints:\n",
    "        codon_allele_dict[gen] = {}\n",
    "        for idx in site_list:\n",
    "            codon_allele_dict[gen][idx] = {}\n",
    "            for codon in CODONS:\n",
    "                codon_allele_dict[gen][idx][codon] = 0\n",
    "\n",
    "            codon_allele_dict[gen][idx][raw_codon[site_list.index(idx)]] = total_count[timepoints.index(gen)]\n",
    "    \n",
    "    reference_list = list(reference_sequence)\n",
    "    for i in range(allele_counts_table_no_wt.shape[0]):\n",
    "        print(\"Progress {:2.1%}\".format(i / allele_counts_table_no_wt.shape[0]), end=\"\\r\")\n",
    "        variants_allele = allele_counts_table_no_wt.iloc[i].variants\n",
    "        mutation_number = allele_counts_table_no_wt.iloc[i].tolist()[1:]\n",
    "        temp = [int(integer) for integer in mutation_number]\n",
    "        mutation_number = temp\n",
    "        nucleotide = [x for x in variants_allele if x.isalpha()]\n",
    "        variant_site = re.findall(\"(\\d+)\", variants_allele)\n",
    "        nucleotide = nucleotide[1:]\n",
    "        variant_list = reference_list.copy()\n",
    "        for j in range(len(variant_site)):\n",
    "            variant_list[int(variant_site[j])-1] = nucleotide[2 * j + 1]\n",
    "        variant_sequence = ''.join(variant_list)\n",
    "        variant_codon = [variant_sequence[i:i+codon_length] for i in range(0, len(variant_sequence), codon_length)]\n",
    "        for r, n, idx in zip(raw_codon, variant_codon, site_list):\n",
    "            if r != n:\n",
    "                for gen in timepoints:\n",
    "                    codon_allele_dict[gen][idx][r] -= mutation_number[timepoints.index(gen)]\n",
    "                    codon_allele_dict[gen][idx][n] += mutation_number[timepoints.index(gen)]\n",
    "\n",
    "    allele_counts_list = []\n",
    "    for gen, site_codon_counts in codon_allele_dict.items():\n",
    "        for site, codon_counts in site_codon_counts.items():\n",
    "            for codon, counts in codon_counts.items():\n",
    "                allele_counts_list.append([rep, gen, site, codon, counts])\n",
    "\n",
    "    codon_counts_table = pd.DataFrame(data = allele_counts_list, columns = allele_counts_columns)\n",
    "    codon_counts_table.to_csv(save_path, sep = ',', index = False, compression = 'zip')\n",
    "    return df_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7e339fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucleotide_file_to_counts_double_allele(nucleotide_file_name, reference_sequence, site_start, site_end, timepoints, rep, table_col_name, save_path):\n",
    "    codon_length = 3\n",
    "    df_data = pd.read_csv(nucleotide_file_name, low_memory=False)\n",
    "    df_data = df_data.fillna(0)\n",
    "    df_data = df_data.drop([0, 1, 2], axis = 0)\n",
    "    df_data = df_data.drop(df_data.columns[0], axis = 1)\n",
    "    df_data.reset_index(drop=True, inplace=True)\n",
    "    df_data.columns = df_data.iloc[0]\n",
    "    df_data = df_data.drop([0], axis = 0)\n",
    "    \n",
    "\n",
    "    CODONS = ['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT',   # Tri-nucleotide units table\n",
    "              'AGA', 'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT',\n",
    "              'CAA', 'CAC', 'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT',\n",
    "              'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC', 'CTG', 'CTT',\n",
    "              'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT',\n",
    "              'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT',\n",
    "              'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT',\n",
    "              'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG', 'TTT']   \n",
    "\n",
    "    df_data[df_data['hgvs_nt'].str.contains('X', regex=False)]\n",
    "    df_data = df_data[~df_data.hgvs_nt.str.contains('X', regex=False)]\n",
    "    \n",
    "    df_frequency = df_data.loc[:,df_data.columns[2]:].astype('float')\n",
    "    df_frequency.loc[:,df_frequency.columns[2]:] = df_frequency.loc[:,df_frequency.columns[2]:].div(df_frequency.sum(axis=1),axis=0)\n",
    "    site_list = list(range(site_start, site_end+1))\n",
    "    raw_codon = [reference_sequence[i:i+codon_length] for i in range(0, len(reference_sequence), codon_length)]\n",
    "    allele_counts_columns = ['replicate', 'generation', 'site_1', 'codon_1', 'site_2', 'codon_2', 'counts']\n",
    "    allele_counts_table = df_data[table_col_name]\n",
    "\n",
    "    temp = allele_counts_table.columns.tolist()[0]\n",
    "    allele_counts_table = allele_counts_table.rename(columns={temp: 'variants'})\n",
    "    count_table_columns = allele_counts_table.columns.tolist()\n",
    "    allele_counts_table[allele_counts_table['variants'] == '_wt']\n",
    "\n",
    "    allele_counts_table_no_wt = allele_counts_table.drop(allele_counts_table.index[allele_counts_table['variants'] == '_wt'])\n",
    "\n",
    "    total_count = []\n",
    "    total_mut = []\n",
    "    total_wt  = []\n",
    "    for i in range(len(timepoints)):\n",
    "        counts_all = allele_counts_table[count_table_columns[i+1]].tolist()\n",
    "        temp = [int(integer) for integer in counts_all]\n",
    "        counts_all = temp\n",
    "        summation_all = sum(counts_all)\n",
    "        total_count.append(summation_all)\n",
    "        counts_mut = allele_counts_table_no_wt[count_table_columns[i+1]].tolist()\n",
    "        temp = [int(integer) for integer in counts_mut]\n",
    "        counts_mut = temp\n",
    "        summation_mut = sum(counts_mut)\n",
    "        total_mut.append(summation_mut)\n",
    "        summation_wt = summation_all - summation_mut\n",
    "        total_wt.append(summation_wt)\n",
    "\n",
    "    length_site_list = len(site_list)\n",
    "    length_codon_list = len(CODONS)\n",
    "    codon_allele_dict = {}\n",
    "    for gen in timepoints:\n",
    "        codon_allele_dict[gen] = {}\n",
    "        for idx_i in range(length_site_list):\n",
    "            codon_allele_dict[gen][site_list[idx_i]] = {}\n",
    "            codon_allele_dict[gen][site_list[idx_i]][raw_codon[idx_i]] = {}\n",
    "            for idx_j in range(idx_i+1, length_site_list):\n",
    "                codon_allele_dict[gen][site_list[idx_i]][raw_codon[idx_i]][site_list[idx_j]] = {}\n",
    "                codon_allele_dict[gen][site_list[idx_i]][raw_codon[idx_i]][site_list[idx_j]][raw_codon[idx_j]] = total_count[timepoints.index(gen)]\n",
    "\n",
    "    reference_list = list(reference_sequence)\n",
    "\n",
    "    for i in range(allele_counts_table_no_wt.shape[0]):\n",
    "        print(\"Progress {:2.1%}\".format(i / allele_counts_table_no_wt.shape[0]), end=\"\\r\")\n",
    "        variants_allele = allele_counts_table_no_wt.iloc[i].variants\n",
    "        mutation_number = allele_counts_table_no_wt.iloc[i].tolist()[1:]\n",
    "        temp = [int(integer) for integer in mutation_number]\n",
    "        mutation_number = temp\n",
    "        nucleotide = [x for x in variants_allele if x.isalpha()]\n",
    "        variant_site = re.findall(\"(\\d+)\", variants_allele)\n",
    "        nucleotide = nucleotide[1:]\n",
    "        variant_list = reference_list.copy()\n",
    "        for j in range(len(variant_site)):\n",
    "            variant_list[int(variant_site[j])-1] = nucleotide[2 * j + 1]\n",
    "        variant_sequence = ''.join(variant_list)\n",
    "        variant_codon = [variant_sequence[i:i+codon_length] for i in range(0, len(variant_sequence), codon_length)]\n",
    "        variant_site = []\n",
    "\n",
    "        for r, n, idx in zip(raw_codon, variant_codon, site_list):\n",
    "            if r != n:\n",
    "                variant_site.append(idx)\n",
    "\n",
    "        double_variant = []\n",
    "        for v_site in variant_site:\n",
    "            v_site_index = site_list.index(v_site)\n",
    "            for j in range(v_site_index):\n",
    "                double_variant.append([site_list[j], v_site])\n",
    "            for j in range(v_site_index+1, len(site_list)):\n",
    "                double_variant.append([v_site, site_list[j]])\n",
    "\n",
    "        for d_v in double_variant:\n",
    "            site_i = d_v[0]\n",
    "            site_j = d_v[1]\n",
    "            idx_i = site_list.index(site_i)\n",
    "            idx_j = site_list.index(site_j)\n",
    "            codon_i = variant_codon[idx_i]\n",
    "            codon_j = variant_codon[idx_j]\n",
    "\n",
    "            for gen in timepoints:\n",
    "                codon_allele_dict[gen][site_i][raw_codon[idx_i]][site_j][raw_codon[idx_j]] -= mutation_number[timepoints.index(gen)]\n",
    "                if codon_i not in codon_allele_dict[gen][site_i].keys():\n",
    "                    codon_allele_dict[gen][site_i][codon_i] = {}\n",
    "                    codon_allele_dict[gen][site_i][codon_i][site_j] = {}\n",
    "                    codon_allele_dict[gen][site_i][codon_i][site_j][codon_j] = mutation_number[timepoints.index(gen)]\n",
    "                else:\n",
    "                    if site_j not in codon_allele_dict[gen][site_i][codon_i].keys():\n",
    "                        codon_allele_dict[gen][site_i][codon_i][site_j] = {}\n",
    "                        codon_allele_dict[gen][site_i][codon_i][site_j][codon_j] = mutation_number[timepoints.index(gen)]\n",
    "                    else:\n",
    "                        if codon_j not in codon_allele_dict[gen][site_i][codon_i][site_j].keys():\n",
    "                            codon_allele_dict[gen][site_i][codon_i][site_j][codon_j] = mutation_number[timepoints.index(gen)]\n",
    "                        else:\n",
    "                            codon_allele_dict[gen][site_i][codon_i][site_j][codon_j] += mutation_number[timepoints.index(gen)]\n",
    "\n",
    "        if len(variant_site)>1:\n",
    "            error_deletion = list(combinations(variant_site, 2))\n",
    "            for item in error_deletion:\n",
    "                site_i = item[0]\n",
    "                site_j = item[1]\n",
    "                idx_i = site_list.index(site_i)\n",
    "                idx_j = site_list.index(site_j)\n",
    "                codon_i = variant_codon[idx_i]\n",
    "                codon_j = variant_codon[idx_j]\n",
    "                for gen in timepoints:\n",
    "                    codon_allele_dict[gen][site_i][raw_codon[idx_i]][site_j][raw_codon[idx_j]] += mutation_number[timepoints.index(gen)]\n",
    "                    codon_allele_dict[gen][site_i][codon_i][site_j][codon_j] -= mutation_number[timepoints.index(gen)]\n",
    "\n",
    "\n",
    "    allele_counts_list = []\n",
    "    for gen, site_codon_counts in codon_allele_dict.items():\n",
    "        for site_i, codoni_sitej_codonj_countj in site_codon_counts.items():\n",
    "            for codon_i, sitej_codonj_countj in codoni_sitej_codonj_countj.items():\n",
    "                for site_j, codonj_countj in sitej_codonj_countj.items():\n",
    "                    for codon_j, count_j in codonj_countj.items():\n",
    "                        allele_counts_list.append([rep, gen, site_i, codon_i, site_j, codon_j, count_j])\n",
    "\n",
    "\n",
    "    codon_counts_table = pd.DataFrame(data = allele_counts_list, columns = allele_counts_columns)\n",
    "    codon_counts_table.to_csv(save_path, sep = ',', index = False, compression = 'zip')\n",
    "    return df_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95708b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAP1, replicate 1, single allele\n",
      "YAP1, replicate 1, single allele finished\n",
      "YAP1, replicate 1, double allele\n",
      "YAP1, replicate 1, double allele finished\n",
      "YAP1, replicate 2, single allele\n",
      "YAP1, replicate 2, single allele finished\n",
      "YAP1, replicate 2, double allele\n",
      "YAP1, replicate 2, double allele finished\n"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'GACGTTCCACTGCCGGCTGGTTGGGAAATGGCTAAAACTAGTTCTGGTCAGCGTTACTTCCTGAACCACATCGACCAGACCACCACGTGGCAGGACCCGCGT'\n",
    "FILE_NAME = './data/raw_data/YAP1_nucleotide_variant.csv'\n",
    "TARGET_NAME = 'YAP1'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 34\n",
    "GEN = [0, 1, 2, 3]\n",
    "REP = [1, 2]\n",
    "TABLE_COL = {1: ['hgvs_nt','101208_c_0', '101208_c_1', '101208_c_2', '101208_c_3'],\n",
    "             2: ['hgvs_nt','110307_c_0', '110307_c_1', '110307_c_2', '110307_c_3']}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip' \n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e128a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2H_1, replicate 1, single allele\n",
      "Y2H_1, replicate 1, single allele finished\n",
      "Y2H_1, replicate 1, double allele\n",
      "Y2H_1, replicate 1, double allele finished\n",
      "Y2H_1, replicate 2, single allele\n",
      "Y2H_1, replicate 2, single allele finished\n",
      "Y2H_1, replicate 2, double allele\n",
      "Y2H_1, replicate 2, double allele finished\n",
      "Y2H_1, replicate 3, single allele\n",
      "Y2H_1, replicate 3, single allele finished\n",
      "Y2H_1, replicate 3, double allele\n",
      "Y2H_1, replicate 3, double allele finished\n"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'GATTTATCTGCTCTTCGCGTTGAAGAAGTACAAAATGTCATTAATGCTATGCAGAAAATCTTAGAGTGTCCCATCTGCCTGGAGTTGATCAAGGAACCTGTCTCCACAAAGTGTGACCACATATTTTGCAAATTTTGCATGCTGAAACTTCTCAACCAGAAGAAAGGGCCTTCACAGTGTCCTTTATGTAAGAATGATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTTGTTGAAGAGCTATTGAAAATCATTTGTGCTTTTCAGCTTGACACAGGTTTGGAGTATGCAAACAGCTATAATTTTGCAAAAAAGGAAAATAACTCTCCTGAACATCTAAAAGATGAAGTTTCTATCATCCAAAGTATGGGCTACAGAAACCGTGCCAAAAGACTTCTACAGAGTGAACCCGAAAATCCTTCCTTGCAGGAAACCAGTCTCAGTGTCCAACTCTCTAACCTTGGAACTGTGAGAACTCTGAGGACAAAGCAGCGGATACAACCTCAAAGGACGTCTGTCTACATTGAATTGGGATCTGATTCTTCTGAAGATACCGTTAATAAGGCAACTTATTGCAGTGTGGGAGATCAAGAATTGTTACAAATCACCCCTCAAGGAACCAGGGATGAAATCAGTTTGGATTCTGCAAAAAAGGCTGCTTGTGAATTTTCTGAGACGGATGTAACAAATACTGAACATCATCAACCCAGTAATAATGATTTGAACACCACTGAGAAGCGTGCAGCTGAGAGGCATCCAGAAAAGTATCAGGGTAGTTCTGTTTCAAACTTGCATGTGGAGCCATGTGGCACAAATACTCATGCCAGCTCATTACAGCATGAGAACAGCAGTTTATTACTCACTAAAGACAGAATGAATGTAGAAAAGGCTGAGTTC'\n",
    "FILE_NAME = './data/raw_data/Y2H_nucleotide_variant.csv'\n",
    "TARGET_NAME = 'Y2H_1'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 303\n",
    "GEN = [0, 18, 37, 45]\n",
    "REP = [1, 2, 3]\n",
    "TABLE_COL = {1: ['hgvs_nt','Y2H_1_Rep1_c_0', 'Y2H_1_Rep1_c_18', 'Y2H_1_Rep1_c_37', 'Y2H_1_Rep1_c_45'],\n",
    "             2: ['hgvs_nt','Y2H_1_Rep2_c_0', 'Y2H_1_Rep2_c_18', 'Y2H_1_Rep2_c_37', 'Y2H_1_Rep2_c_45'],\n",
    "             3: ['hgvs_nt','Y2H_1_Rep3_c_0', 'Y2H_1_Rep3_c_18', 'Y2H_1_Rep3_c_37', 'Y2H_1_Rep3_c_45']}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip' \n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe8ead38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y2H_2, replicate 1, single allele\n",
      "Y2H_2, replicate 1, single allele finished\n",
      "Y2H_2, replicate 1, double allele\n",
      "Y2H_2, replicate 1, double allele finished\n",
      "Y2H_2, replicate 2, single allele\n",
      "Y2H_2, replicate 2, single allele finished\n",
      "Y2H_2, replicate 2, double allele\n",
      "Y2H_2, replicate 2, double allele finished\n",
      "Y2H_2, replicate 3, single allele\n",
      "Y2H_2, replicate 3, single allele finished\n",
      "Y2H_2, replicate 3, double allele\n",
      "Y2H_2, replicate 3, double allele finished\n"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'GATTTATCTGCTCTTCGCGTTGAAGAAGTACAAAATGTCATTAATGCTATGCAGAAAATCTTAGAGTGTCCCATCTGCCTGGAGTTGATCAAGGAACCTGTCTCCACAAAGTGTGACCACATATTTTGCAAATTTTGCATGCTGAAACTTCTCAACCAGAAGAAAGGGCCTTCACAGTGTCCTTTATGTAAGAATGATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTTGTTGAAGAGCTATTGAAAATCATTTGTGCTTTTCAGCTTGACACAGGTTTGGAGTATGCAAACAGCTATAATTTTGCAAAAAAGGAAAATAACTCTCCTGAACATCTAAAAGATGAAGTTTCTATCATCCAAAGTATGGGCTACAGAAACCGTGCCAAAAGACTTCTACAGAGTGAACCCGAAAATCCTTCCTTGCAGGAAACCAGTCTCAGTGTCCAACTCTCTAACCTTGGAACTGTGAGAACTCTGAGGACAAAGCAGCGGATACAACCTCAAAGGACGTCTGTCTACATTGAATTGGGATCTGATTCTTCTGAAGATACCGTTAATAAGGCAACTTATTGCAGTGTGGGAGATCAAGAATTGTTACAAATCACCCCTCAAGGAACCAGGGATGAAATCAGTTTGGATTCTGCAAAAAAGGCTGCTTGTGAATTTTCTGAGACGGATGTAACAAATACTGAACATCATCAACCCAGTAATAATGATTTGAACACCACTGAGAAGCGTGCAGCTGAGAGGCATCCAGAAAAGTATCAGGGTAGTTCTGTTTCAAACTTGCATGTGGAGCCATGTGGCACAAATACTCATGCCAGCTCATTACAGCATGAGAACAGCAGTTTATTACTCACTAAAGACAGAATGAATGTAGAAAAGGCTGAGTTC'\n",
    "FILE_NAME = './data/raw_data/Y2H_nucleotide_variant.csv'\n",
    "TARGET_NAME = 'Y2H_2'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 303\n",
    "GEN = [0, 16, 41, 64]\n",
    "REP = [1, 2, 3]\n",
    "TABLE_COL = {1: ['hgvs_nt','Y2H_2_Rep1_c_0', 'Y2H_2_Rep1_c_16', 'Y2H_2_Rep1_c_41', 'Y2H_2_Rep1_c_64'],\n",
    "             2: ['hgvs_nt','Y2H_2_Rep2_c_0', 'Y2H_2_Rep2_c_16', 'Y2H_2_Rep2_c_41', 'Y2H_2_Rep2_c_64'],\n",
    "             3: ['hgvs_nt','Y2H_2_Rep3_c_0', 'Y2H_2_Rep3_c_16', 'Y2H_2_Rep3_c_41', 'Y2H_2_Rep3_c_64']}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip' \n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13897791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3, replicate 1, single allele\n",
      "E3, replicate 1, single allele finished\n",
      "E3, replicate 1, double allele\n",
      "E3, replicate 1, double allele finished\n",
      "E3, replicate 2, single allele\n",
      "E3, replicate 2, single allele finished\n",
      "E3, replicate 2, double allele\n",
      "E3, replicate 2, double allele finished\n",
      "E3, replicate 3, single allele\n",
      "E3, replicate 3, single allele finished\n",
      "E3, replicate 3, double allele\n",
      "E3, replicate 3, double allele finished\n",
      "E3, replicate 4, single allele\n",
      "E3, replicate 4, single allele finished\n",
      "E3, replicate 4, double allele\n",
      "E3, replicate 4, double allele finished\n",
      "E3, replicate 5, single allele\n",
      "E3, replicate 5, single allele finished\n",
      "E3, replicate 5, double allele\n",
      "E3, replicate 5, double allele finished\n",
      "E3, replicate 6, single allele\n",
      "E3, replicate 6, single allele finished\n",
      "E3, replicate 6, double allele\n",
      "E3, replicate 6, double allele finished\n"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'GATTTATCTGCTCTTCGCGTTGAAGAAGTACAAAATGTCATTAATGCTATGCAGAAAATCTTAGAGTGTCCCATCTGCCTGGAGTTGATCAAGGAACCTGTCTCCACAAAGTGTGACCACATATTTTGCAAATTTTGCATGCTGAAACTTCTCAACCAGAAGAAAGGGCCTTCACAGTGTCCTTTATGTAAGAATGATATAACCAAAAGGAGCCTACAAGAAAGTACGAGATTTAGTCAACTTGTTGAAGAGCTATTGAAAATCATTTGTGCTTTTCAGCTTGACACAGGTTTGGAGTATGCAAACAGCTATAATTTTGCAAAAAAGGAAAATAACTCTCCTGAACATCTAAAAGATGAAGTTTCTATCATCCAAAGTATGGGCTACAGAAACCGTGCCAAAAGACTTCTACAGAGTGAACCCGAAAATCCTTCCTTGCAGGAAACCAGTCTCAGTGTCCAACTCTCTAACCTTGGAACTGTGAGAACTCTGAGGACAAAGCAGCGGATACAACCTCAAAGGACGTCTGTCTACATTGAATTGGGATCTGATTCTTCTGAAGATACCGTTAATAAGGCAACTTATTGCAGTGTGGGAGATCAAGAATTGTTACAAATCACCCCTCAAGGAACCAGGGATGAAATCAGTTTGGATTCTGCAAAAAAGGCTGCTTGTGAATTTTCTGAGACGGATGTAACAAATACTGAACATCATCAACCCAGTAATAATGATTTGAACACCACTGAGAAGCGTGCAGCTGAGAGGCATCCAGAAAAGTATCAGGGTAGTTCTGTTTCAAACTTGCATGTGGAGCCATGTGGCACAAATACTCATGCCAGCTCATTACAGCATGAGAACAGCAGTTTATTACTCACTAAAGACAGAATGAATGTAGAAAAGGCTGAGTTC'\n",
    "FILE_NAME = './data/raw_data/Y2H_nucleotide_variant.csv'\n",
    "TARGET_NAME = 'E3'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 303\n",
    "GEN = [0, 1, 2, 3, 4, 5]\n",
    "REP = [1, 2, 3, 4, 5, 6]\n",
    "TABLE_COL = {1: ['hgvs_nt','PlusE2NewRep3_c_0', 'PlusE2NewRep3_c_1', 'PlusE2NewRep3_c_2', 'PlusE2NewRep3_c_3', 'PlusE2NewRep3_c_4', 'PlusE2NewRep3_c_5'],\n",
    "             2: ['hgvs_nt','PlusE2NewRep4_c_0', 'PlusE2NewRep4_c_1', 'PlusE2NewRep4_c_2', 'PlusE2NewRep4_c_3', 'PlusE2NewRep4_c_4', 'PlusE2NewRep4_c_5'],\n",
    "             3: ['hgvs_nt','PlusE2NewRep5_c_0', 'PlusE2NewRep5_c_1', 'PlusE2NewRep5_c_2', 'PlusE2NewRep5_c_3', 'PlusE2NewRep5_c_4', 'PlusE2NewRep5_c_5'],\n",
    "             4: ['hgvs_nt','PlusE2Rep3_c_0', 'PlusE2Rep3_c_1', 'PlusE2Rep3_c_2', 'PlusE2Rep3_c_3', 'PlusE2Rep3_c_4', 'PlusE2Rep3_c_5'],\n",
    "             5: ['hgvs_nt','PlusE2Rep4_c_0', 'PlusE2Rep4_c_1', 'PlusE2Rep4_c_2', 'PlusE2Rep4_c_3', 'PlusE2Rep4_c_4', 'PlusE2Rep4_c_5'],\n",
    "             6: ['hgvs_nt','PlusE2Rep5_c_0', 'PlusE2Rep5_c_1', 'PlusE2Rep5_c_2', 'PlusE2Rep5_c_3', 'PlusE2Rep5_c_4', 'PlusE2Rep5_c_5']}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip' \n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72622770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ube4b, replicate 1, single allele\n",
      "Ube4b, replicate 1, single allele finished\n",
      "Ube4b, replicate 1, double allele\n",
      "Ube4b, replicate 1, double allele finished\n",
      "Ube4b, replicate 2, single allele\n",
      "Ube4b, replicate 2, single allele finished\n",
      "Ube4b, replicate 2, double allele\n",
      "Ube4b, replicate 2, double allele finished\n"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'ATAGAGAAGTTTAAACTTCTTGCAGAGAAAGTGGAGGAAATCGTGGCAAAGAATGCGCGGGCAGAAATAGACTACAGCGATGCCCCGGACGAGTTCAGAGACCCTCTGATGGACACCCTGATGACCGATCCCGTGAGACTGCCCTCTGGCACCGTCATGGACCGTTCTATCATCCTGCGGCATCTGCTCAACTCCCCCACCGACCCCTTCAACCGCCAGATGCTGACTGAGAGCATGCTGGAGCCAGTGCCAGAGCTAAAGGAGCAGATTCAGGCCTGGATGAGAGAGAAACAGAGCAGTGACCACTGA'\n",
    "FILE_NAME = './data/raw_data/Ube4b_nucleotide_variant.csv'\n",
    "TARGET_NAME = 'Ube4b'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 103\n",
    "GEN = [0, 1, 2, 3]\n",
    "REP = [1, 2]\n",
    "TABLE_COL = {1: ['hgvs_nt', 'Rep_2_c_0', 'Rep_2_c_1','Rep_2_c_2', 'Rep_2_c_3'],\n",
    "             2: ['hgvs_nt', 'Rep_3_c_0', 'Rep_3_c_1','Rep_3_c_2', 'Rep_3_c_3'],}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "083361dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TpoR, replicate 1, single allele\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc9 in position 10: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6d55237ef166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', replicate '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', single allele'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mSAVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOUNT_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTARGET_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_single_allele_rep'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mnucleotide_file_to_counts_single_allele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mREFER_SEQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTABLE_COL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', replicate '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', single allele finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', replicate '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', double allele'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-626e6ab95fd3>\u001b[0m in \u001b[0;36mnucleotide_file_to_counts_single_allele\u001b[0;34m(nucleotide_file_name, reference_sequence, site_start, site_end, timepoints, rep, table_col_name, save_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnucleotide_file_to_counts_single_allele\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnucleotide_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimepoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_col_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcodon_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnucleotide_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc9 in position 10: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "REFER_SEQ = 'ACCGAGACCGCCTGGATCTCCTTGGTGACCGCTCTGCATCTAGTGCTGGGCCTCAGCGCCGTCCTGGGCCTGCTGCTGCTGAGGTGGCAGTTT'\n",
    "FILE_NAME = './data/raw_data/TpoR_nucleotide_counts.csv'\n",
    "TARGET_NAME = 'TpoR'\n",
    "COUNT_PATH = './outputs/allele_counts/'\n",
    "START = 1\n",
    "END = 31\n",
    "GEN = [0, 1]\n",
    "REP = [1, 2, 3, 4, 5, 6]\n",
    "TABLE_COL = {1: ['hgvs_nt', 'Replicate_A_c_0', 'Replicate_A_c_1'],\n",
    "             2: ['hgvs_nt', 'Replicate_B_c_0', 'Replicate_B_c_1'],\n",
    "             3: ['hgvs_nt', 'Replicate_C_c_0', 'Replicate_C_c_1'],\n",
    "             4: ['hgvs_nt', 'Replicate_D_c_0', 'Replicate_D_c_1'],\n",
    "             5: ['hgvs_nt', 'Replicate_E_c_0', 'Replicate_E_c_1'],\n",
    "             6: ['hgvs_nt', 'Replicate_F_c_0', 'Replicate_F_c_1']}\n",
    "\n",
    "for rep in REP:\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_single_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_single_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', single allele finished')\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele')\n",
    "    SAVE_PATH = COUNT_PATH + TARGET_NAME + '_double_allele_rep' + str(rep) + '.csv.zip'\n",
    "    nucleotide_file_to_counts_double_allele(FILE_NAME, REFER_SEQ, START, END, GEN, rep, TABLE_COL[rep], SAVE_PATH)\n",
    "    print(TARGET_NAME + ', replicate '+str(rep)+', double allele finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4064ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
